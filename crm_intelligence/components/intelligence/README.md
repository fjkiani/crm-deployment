# Intelligence Components

Clean, modular components that break down the original 1100-line monolithic intelligence gathering script into focused, maintainable pieces.

## ðŸ—ï¸ Component Architecture

```
intelligence/
â”œâ”€â”€ intelligence_gatherer.py    # ðŸ” API interactions & raw data collection
â”œâ”€â”€ data_processor.py          # ðŸ”„ Data extraction & normalization
â”œâ”€â”€ profile_builder.py         # ðŸ—ï¸ Structured profile construction
â”œâ”€â”€ lead_selector.py           # ðŸŽ¯ Lead evaluation & selection
â”œâ”€â”€ intelligence_orchestrator.py # ðŸŽ¼ Component coordination
â”œâ”€â”€ intelligence_runner.py     # ðŸš€ Main execution script
â””â”€â”€ README.md                  # ðŸ“š This documentation
```

## ðŸŽ¯ Component Responsibilities

### IntelligenceGatherer (`intelligence_gatherer.py`)
**Purpose**: Raw data collection from external APIs
**Size**: ~120 lines
**Methods**:
- `search()` - Core Tavily API interaction
- `gather_company_overview()` - Basic company information
- `gather_executive_info()` - Leadership team data
- `gather_investment_info()` - Portfolio and investment data
- `gather_news_info()` - Recent developments and news
- `gather_partnership_info()` - Network and partnership data

### DataProcessor (`data_processor.py`)
**Purpose**: Extract and normalize structured data from raw search results
**Size**: ~160 lines
**Methods**:
- `extract_executive_info()` - Parse executive information
- `extract_investment_info()` - Parse investment data
- `extract_news_info()` - Parse news and categorize
- `extract_partnership_info()` - Parse partnership data

### ProfileBuilder (`profile_builder.py`)
**Purpose**: Build structured intelligence profiles from processed data
**Size**: ~180 lines
**Methods**:
- `build_executive_profile()` - Leadership structure analysis
- `build_investment_profile()` - Investment focus analysis
- `build_news_profile()` - News categorization
- `build_partnership_profile()` - Network analysis
- `build_comprehensive_profile()` - Complete profile assembly

### LeadSelector (`lead_selector.py`)
**Purpose**: Evaluate and select high-value leads for intelligence gathering
**Size**: ~120 lines
**Methods**:
- `select_high_value_leads()` - Score and rank leads
- `load_leads_from_file()` - Load leads data
- `filter_leads_by_criteria()` - Apply selection criteria
- `get_lead_statistics()` - Generate dataset statistics

### IntelligenceOrchestrator (`intelligence_orchestrator.py`)
**Purpose**: Coordinate components to provide complete intelligence workflow
**Size**: ~100 lines
**Methods**:
- `process_company()` - Single company intelligence gathering
- `process_multiple_companies()` - Batch processing
- `select_and_process_leads()` - End-to-end workflow

## ðŸš€ Quick Start

### Basic Usage
```python
from intelligence_orchestrator import IntelligenceOrchestrator

# Configure
config = {"tavily_api_key": "your_key_here"}

# Initialize
orchestrator = IntelligenceOrchestrator(config)

# Process a company
profile = orchestrator.process_company("3EDGE Asset Management")
print(f"Confidence: {profile['confidence_metrics']['overall_confidence']}")
```

### Advanced Usage
```python
# Select and process high-value leads
leads_file = "data/output/organized_leads.json"
profiles = orchestrator.select_and_process_leads(leads_file, limit=5)

# Process multiple companies
companies = ["Company A", "Company B", "Company C"]
profiles = orchestrator.process_multiple_companies(companies)
```

### Run Complete Workflow
```bash
cd crm_intelligence/components/intelligence
python intelligence_runner.py
```

## ðŸ”§ Configuration

### Required Environment Variables
```bash
export TAVILY_API_KEY="your_tavily_api_key_here"
```

### Optional Configuration
```python
config = {
    "tavily_api_key": "your_key",        # Required
    "max_results": 5,                   # Default: 5
    "timeout": 30,                      # Default: 30 seconds
}
```

## ðŸ“Š Component Benefits

### âœ… Single Responsibility
Each component has one clear job:
- **Gatherer**: API calls and raw data
- **Processor**: Data extraction and cleaning
- **Builder**: Profile construction and analysis
- **Selector**: Lead evaluation and prioritization
- **Orchestrator**: Workflow coordination

### âœ… Easy Testing
Each component can be tested independently:
```python
# Test just the data processor
processor = DataProcessor(config)
result = processor.extract_executive_info(test_data)
assert len(result) > 0
```

### âœ… Easy Modification
Want to change how executives are extracted?
- Modify only `DataProcessor.extract_executive_info()`
- No need to touch other components
- Isolated changes reduce risk

### âœ… Easy Extension
Want to add a new intelligence source?
- Add method to `IntelligenceGatherer`
- Update `DataProcessor` if needed
- Orchestrator automatically includes it

## ðŸ”„ Migration from Monolithic Code

### Original: 1100-line file
```python
# One massive file with everything mixed together
class DeepIntelligenceScout:
    def search_tavily(self): pass
    def extract_executive_info(self): pass
    def build_executive_profile(self): pass
    # ... 50+ methods all in one class
```

### New: Modular Components
```python
# Clean separation of concerns
gatherer = IntelligenceGatherer(config)      # API calls
processor = DataProcessor(config)            # Data extraction
builder = ProfileBuilder(config)             # Profile building
orchestrator = IntelligenceOrchestrator(config)  # Coordination
```

## ðŸ“ˆ Performance Comparison

| Aspect | Original (1100 lines) | New Modular |
|--------|----------------------|-------------|
| **File Size** | 1100 lines | 50-180 lines each |
| **Testing** | Hard to isolate | Easy unit tests |
| **Modification** | Risky changes | Isolated changes |
| **Understanding** | Complex | Clear responsibilities |
| **Maintenance** | Difficult | Straightforward |
| **Extension** | Error-prone | Simple addition |

## ðŸŽ¯ Next Steps

1. **Test Individual Components**: Verify each component works independently
2. **Integration Testing**: Test component interactions
3. **Performance Tuning**: Optimize API calls and data processing
4. **Add New Features**: Easy to extend with new intelligence sources
5. **Documentation**: Update this README as components evolve

## ðŸ”§ Development Guidelines

### Adding New Components
1. **Identify Responsibility**: What single job does this component have?
2. **Keep Size Small**: Target 50-150 lines maximum
3. **Clear Interface**: Define input/output contracts clearly
4. **Add Tests**: Include comprehensive unit tests
5. **Update Orchestrator**: Integrate into workflow if needed

### Modifying Existing Components
1. **Isolate Changes**: Only modify the component that owns the responsibility
2. **Preserve Interface**: Don't break existing input/output contracts
3. **Add Tests**: Ensure new functionality is tested
4. **Update Documentation**: Reflect changes in this README

---

**This modular approach transforms a complex, hard-to-maintain monolithic script into a clean, extensible, and maintainable system!** ðŸš€âœ¨
